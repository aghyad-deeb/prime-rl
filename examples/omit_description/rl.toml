inference_gpu_ids = [0,1,2,3,4,5]
trainer_gpu_ids = [6,7]

max_steps = 500

[model]
name = "Qwen/Qwen3-4B"

[wandb]
project = "primerl_vs_verl"
name = "primerl"

[trainer.optim]
lr = 2e-5
weight_decay = 0.0

[trainer.model.experimental.lora]
rank = 8
alpha = 32
dropout = 0.0
target_modules = [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj",
    "gate_proj",
    "up_proj",
    "down_proj"
]

[orchestrator]
batch_size = 48
rollouts_per_example = 16
seq_len = 6000
oversampling_factor = 2.0

[orchestrator.sampling]
max_tokens = 6000

[orchestrator.buffer]
online_difficulty_filtering = true

[[orchestrator.env]]
id = "omit_description"

[inference]
